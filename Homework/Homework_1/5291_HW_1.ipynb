{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13273c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 30\n",
      "T_n = max(x) = 1.983800\n",
      "Jackknife bias estimate = -0.091253\n",
      "Bootstrap bias estimate (B=10000) = -0.039243\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"BiasEst.csv\")    \n",
    "x = df[\"x\"].to_numpy()\n",
    "n = len(x)\n",
    "\n",
    "# Estimator: sample maximum\n",
    "Tn = np.max(x)\n",
    "\n",
    "# Jackknife\n",
    "jack_vals = np.empty(n, dtype=float)\n",
    "for i in range(n):\n",
    "    jack_vals[i] = np.max(np.delete(x, i))\n",
    "\n",
    "T_dot = jack_vals.mean()\n",
    "bias_jack = (n - 1) * (T_dot - Tn)\n",
    "\n",
    "# Bootstrap\n",
    "B = 10000\n",
    "rng = np.random.default_rng(0)  # fixed seed for reproducibility\n",
    "\n",
    "boot_vals = np.empty(B, dtype=float)\n",
    "for b in range(B):\n",
    "    sample = rng.choice(x, size=n, replace=True)\n",
    "    boot_vals[b] = np.max(sample)\n",
    "\n",
    "bias_boot = boot_vals.mean() - Tn\n",
    "\n",
    "# Printout\n",
    "print(f\"n = {n}\")\n",
    "print(f\"T_n = max(x) = {Tn:.6f}\")\n",
    "print(f\"Jackknife bias estimate = {bias_jack:.6f}\")\n",
    "print(f\"Bootstrap bias estimate (B={B}) = {bias_boot:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a19add6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True bias = -0.064516\n",
      "\n",
      "E[T_n] check:\n",
      "  MC mean of T_n = 1.935274\n",
      "  True E[T_n]    = 1.935484\n",
      "\n",
      "Jackknife bias estimator:\n",
      "  mean = -0.062752, sd = 0.060396\n",
      "  MSE vs true bias = 0.003650\n",
      "  MAE vs true bias = 0.045456\n",
      "\n",
      "Bootstrap bias estimator:\n",
      "  mean = -0.035800, sd = 0.024039\n",
      "  MSE vs true bias = 0.001402\n",
      "  MAE vs true bias = 0.033751\n"
     ]
    }
   ],
   "source": [
    "# With MC method\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "K = 10000          # MC replications\n",
    "n = 30\n",
    "theta = 2.0\n",
    "B = 500            \n",
    "rng = np.random.default_rng(123)\n",
    "\n",
    "theta_vec = np.empty(K)\n",
    "bias_jack = np.empty(K)\n",
    "bias_boot = np.empty(K)\n",
    "\n",
    "# True bias of T_n = max(X_i) for Unif(0, theta)\n",
    "true_bias = -theta / (n + 1)\n",
    "\n",
    "# Fast jackknife bias for max\n",
    "\n",
    "def jackknife_bias_max(x: np.ndarray) -> float:\n",
    "    n = x.size\n",
    "    xs = np.sort(x)\n",
    "    m1 = xs[-1]      # max\n",
    "    m2 = xs[-2]      # second max\n",
    "    c = np.sum(x == m1) \n",
    "\n",
    "    # Average of leave-one-out maxima:\n",
    "    # if max appears more than once: all leave-one-out maxima are still m1\n",
    "    # if max appears once: one leave-one-out max becomes m2, others stay m1\n",
    "    if c > 1:\n",
    "        avg_leave1 = m1\n",
    "    else:\n",
    "        avg_leave1 = ((n - 1) * m1 + m2) / n\n",
    "\n",
    "    # Jackknife bias estimate: (n-1)(T_. - T)\n",
    "    return (n - 1) * (avg_leave1 - m1)\n",
    "\n",
    "# Monte Carlo loop\n",
    "for k in range(K):\n",
    "    # simulate sample\n",
    "    x = rng.uniform(0.0, theta, size=n)\n",
    "\n",
    "    # T_n = max\n",
    "    Tn = x.max()\n",
    "    theta_vec[k] = Tn\n",
    "\n",
    "    # jackknife bias estimate\n",
    "    bias_jack[k] = jackknife_bias_max(x)\n",
    "\n",
    "    # bootstrap bias estimate: E*(T*) - T\n",
    "    idx = rng.integers(0, n, size=(B, n))\n",
    "    boot_max = x[idx].max(axis=1)\n",
    "    bias_boot[k] = boot_max.mean() - Tn\n",
    "\n",
    "# Summaries\n",
    "def summarize(arr):\n",
    "    return {\n",
    "        \"mean\": np.mean(arr),\n",
    "        \"sd\": np.std(arr, ddof=1),\n",
    "        \"mse_vs_true_bias\": np.mean((arr - true_bias) ** 2),\n",
    "        \"mae_vs_true_bias\": np.mean(np.abs(arr - true_bias)),\n",
    "    }\n",
    "\n",
    "print(f\"True bias = {true_bias:.6f}\\n\")\n",
    "\n",
    "print(\"E[T_n] check:\")\n",
    "print(f\"  MC mean of T_n = {theta_vec.mean():.6f}\")\n",
    "print(f\"  True E[T_n]    = {(n/(n+1)*theta):.6f}\\n\")\n",
    "\n",
    "sj = summarize(bias_jack)\n",
    "sb = summarize(bias_boot)\n",
    "\n",
    "print(\"Jackknife bias estimator:\")\n",
    "print(f\"  mean = {sj['mean']:.6f}, sd = {sj['sd']:.6f}\")\n",
    "print(f\"  MSE vs true bias = {sj['mse_vs_true_bias']:.6f}\")\n",
    "print(f\"  MAE vs true bias = {sj['mae_vs_true_bias']:.6f}\\n\")\n",
    "\n",
    "print(\"Bootstrap bias estimator:\")\n",
    "print(f\"  mean = {sb['mean']:.6f}, sd = {sb['sd']:.6f}\")\n",
    "print(f\"  MSE vs true bias = {sb['mse_vs_true_bias']:.6f}\")\n",
    "print(f\"  MAE vs true bias = {sb['mae_vs_true_bias']:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
